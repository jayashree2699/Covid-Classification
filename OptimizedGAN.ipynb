{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OptimizedGAN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDvlGP6zxz1x",
        "outputId": "91b23b24-0157-4e4a-8d44-8d836fb9f792"
      },
      "source": [
        "!pip install tensorflow==1.4.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow==1.4.0 (from versions: 1.13.0rc1, 1.13.0rc2, 1.13.1, 1.13.2, 1.14.0rc0, 1.14.0rc1, 1.14.0, 1.15.0rc0, 1.15.0rc1, 1.15.0rc2, 1.15.0rc3, 1.15.0, 1.15.2, 1.15.3, 1.15.4, 1.15.5, 2.0.0a0, 2.0.0b0, 2.0.0b1, 2.0.0rc0, 2.0.0rc1, 2.0.0rc2, 2.0.0, 2.0.1, 2.0.2, 2.0.3, 2.0.4, 2.1.0rc0, 2.1.0rc1, 2.1.0rc2, 2.1.0, 2.1.1, 2.1.2, 2.1.3, 2.2.0rc0, 2.2.0rc1, 2.2.0rc2, 2.2.0rc3, 2.2.0rc4, 2.2.0, 2.2.1, 2.2.2, 2.3.0rc0, 2.3.0rc1, 2.3.0rc2, 2.3.0, 2.3.1, 2.3.2, 2.4.0rc0, 2.4.0rc1, 2.4.0rc2, 2.4.0rc3, 2.4.0rc4, 2.4.0, 2.4.1)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for tensorflow==1.4.0\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8DAAgNgBso1"
      },
      "source": [
        "from keras.optimizers import Optimizer\r\n",
        "from keras import backend as K\r\n",
        "import tensorflow.compat.v1 as tf\r\n",
        "class PSO():\r\n",
        "    def __init__(self, \r\n",
        "                 TF2_model, \r\n",
        "                 update_w = 1E-5,\r\n",
        "                 update_c1 = .1,\r\n",
        "                 update_c2 = 1,\r\n",
        "                 population_size = 10):\r\n",
        "        self.nnmodel = TF2_model\r\n",
        "        self.population_size = population_size\r\n",
        "        self.population = self._createPopulation()\r\n",
        "        self.update_w = update_w\r\n",
        "        self.update_c1 = update_c1\r\n",
        "        self.update_c2 = update_c2\r\n",
        "        self.pbest = {'fitness':tf.zeros([population_size]), \r\n",
        "                      'weights':tf.zeros(self.population['weights'].shape)}\r\n",
        "        self.force_evaluate = True\r\n",
        "    pass \r\n",
        "\r\n",
        "    def _createPopulation(self):\r\n",
        "        self.population = {}\r\n",
        "        # creating the weights\r\n",
        "        weights = self._flattenWeightsTFKeras()\r\n",
        "        self.population['weights'] = tf.stack([tf.random.normal(weights.shape, stddev=.05) for i in range(self.population_size)], axis=0)\r\n",
        "        self.population['velocity'] = tf.stack([tf.random.normal(weights.shape, stddev=.0) for i in range(self.population_size)], axis=0)\r\n",
        "        # self.population['graphs'] = [tf.keras.models.clone_model(self.nnmodel) for i in range(self.population_size)]\r\n",
        "        return self.population\r\n",
        "    pass \r\n",
        "\r\n",
        "    def _flattenWeightsTFKeras(self):\r\n",
        "        flated_weights = tf.Variable(tf.concat([tf.reshape(weights, [-1]) for weights in self.nnmodel.trainable_weights], axis=-1))\r\n",
        "        return flated_weights\r\n",
        "    pass \r\n",
        "\r\n",
        "    def _recoverFlattenWeightsTFKeras(self, model, flated_weights):\r\n",
        "        access_index = 0\r\n",
        "        for model_tesnsor in model.trainable_weights:\r\n",
        "            element_shape = model_tesnsor.shape.as_list()\r\n",
        "            element_number = np.ones(element_shape).sum().astype('int')\r\n",
        "            model_tesnsor.assign(tf.reshape(flated_weights[access_index:access_index + element_number], element_shape))\r\n",
        "            access_index += element_number\r\n",
        "        pass\r\n",
        "        return model\r\n",
        "    pass \r\n",
        "\r\n",
        "    def update_fitness(self, fitness_function):\r\n",
        "        fitness_rec = []\r\n",
        "        for ind_index in range(self.population_size):\r\n",
        "            self._recoverFlattenWeightsTFKeras(self.nnmodel, self.population['weights'][ind_index])\r\n",
        "            fitness_rec.append(fitness_function())\r\n",
        "        pass \r\n",
        "        return tf.concat(fitness_rec, axis=0)\r\n",
        "    pass \r\n",
        "\r\n",
        "    def minimize(self, fitness_function):\r\n",
        "        #print('PSO')\r\n",
        "        # get fitnesses of each individual\r\n",
        "        fitness_rec = self.update_fitness(fitness_function)\r\n",
        "        # print(fitness_rec)\r\n",
        "        #print('inside PSO optimization')\r\n",
        "\r\n",
        "        # take change to jump out of the outlier\r\n",
        "        if self.force_evaluate:\r\n",
        "            self.force_evaluate = False\r\n",
        "            self.pbest['fitness'] = tf.identity(fitness_rec)\r\n",
        "            self.pbest['weights'] = tf.identity(self.population['weights'])\r\n",
        "        else :\r\n",
        "            self.pbest['fitness'] = tf.identity(fitness_rec + self.pbest['fitness'])/2 \r\n",
        "        pass \r\n",
        "        \r\n",
        "        # update pbest memory\r\n",
        "        rec_cmp = tf.cast(tf.math.less(self.pbest['fitness'], fitness_rec), dtype=tf.float32)\r\n",
        "        self.pbest['fitness'] = tf.identity(self.pbest['fitness'] * rec_cmp + fitness_rec * (-1 * rec_cmp + 1)) # update the pbest fitness\r\n",
        "        rec_cmp = tf.reshape(rec_cmp, [-1, 1])\r\n",
        "        # print(rec_cmp)\r\n",
        "        self.pbest['weights'] = tf.identity(self.pbest['weights'] * rec_cmp + self.population['weights'] * (-1 * rec_cmp + 1)) # update the pbest weights\r\n",
        "        \r\n",
        "        # create gbest tensors\r\n",
        "        # gbest = tf.identity(self.population['weights'][tf.argmin(fitness_rec)])\r\n",
        "        gbest = tf.identity(self.pbest['weights'][tf.argmin(self.pbest['fitness'])])\r\n",
        "\r\n",
        "        # update population \r\n",
        "        # vid+1 = w∙vid+c1∙rand()∙(pid-xid)+c2∙Rand()∙(pgd-xid) \r\n",
        "        # xid+1 = xid+vid\r\n",
        "        self.population['velocity'] = tf.identity(\r\n",
        "                                      self.update_w * tf.identity(self.population['velocity']) +\\\r\n",
        "                                    #   self.update_c1 * tf.math.abs(tf.random.normal(self.population['velocity'].shape, stddev=.05, dtype=tf.float32)) * tf.identity(self.pbest['weights'] - self.population['weights']) +\\\r\n",
        "                                    #   self.update_c2 * tf.math.abs(tf.random.normal(self.population['velocity'].shape, stddev=.05, dtype=tf.float32)) * tf.identity(gbest - self.population['weights'])\r\n",
        "                                      self.update_c1 * tf.math.abs(tf.random.normal([self.population_size, 1], stddev=1E-4, dtype=tf.float32)) * tf.identity(self.pbest['weights'] - self.population['weights']) +\\\r\n",
        "                                      self.update_c2 * tf.math.abs(tf.random.normal([self.population_size, 1], stddev=1E-4, dtype=tf.float32)) * tf.identity(gbest - self.population['weights'])\r\n",
        "                                      \r\n",
        "                                      )\r\n",
        "        self.population['weights'] = tf.identity(self.population['velocity'] + self.population['weights'])\r\n",
        "\r\n",
        "        return self.pbest['fitness'][tf.argmin(self.pbest['fitness'])]\r\n",
        "    pass \r\n",
        "\r\n",
        "    def getTopModel(self, fitness_function):\r\n",
        "        # get fitnesses of each individual\r\n",
        "        fitness_rec = self.update_fitness(fitness_function)\r\n",
        "\r\n",
        "        # create gbest tensors\r\n",
        "        selected_ind = self.pbest['weights'][tf.argmax(fitness_rec)] \r\n",
        "\r\n",
        "        #set the wieghts to discriminator\r\n",
        "        self._recoverFlattenWeightsTFKeras(self.nnmodel, selected_ind)\r\n",
        "        return self.nnmodel\r\n",
        "    pass\r\n",
        "\r\n",
        "pass "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPT4GDK6frCo",
        "outputId": "323671ba-578d-4b32-d038-0a2de0efd76f"
      },
      "source": [
        "import datetime\r\n",
        "import os\r\n",
        "import numpy as np\r\n",
        "from glob import glob\r\n",
        "from PIL import Image\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "IMAGE_SIZE = 64\r\n",
        "INPUT_DATA_DIR = \"/content/drive/MyDrive/Data/COVID/COVID/data-covid/Covid/\" # Path to the folder with input images. For more info check simspons_dataset.txt\r\n",
        "OUTPUT_DIR = './{date:%Y-%m-%d_%H:%M:%S}/'.format(date=datetime.datetime.now())\r\n",
        "if not os.path.exists(OUTPUT_DIR):\r\n",
        "    os.makedirs(OUTPUT_DIR)\r\n",
        "\r\n",
        "\r\n",
        "# In[ ]:\r\n",
        "# In[ ]:\r\n",
        "\r\n",
        "\r\n",
        "# Training\r\n",
        "input_images = np.asarray([np.asarray(Image.open(file).convert('RGB').resize((IMAGE_SIZE, IMAGE_SIZE))) for file in glob(INPUT_DATA_DIR + '*')])\r\n",
        "print (\"Input: \" + str(input_images.shape))\r\n",
        "\r\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: (500, 64, 64, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQaC3u_XfoLl"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYCZ21r0cv08",
        "outputId": "8beacc76-d7db-4108-93d3-7d4522156f99"
      },
      "source": [
        "noise_dim = 100\r\n",
        "image_shape = (64,64,3)\r\n",
        "from tensorflow.keras.models import Sequential,Model\r\n",
        "from tensorflow.keras.layers import UpSampling2D, Conv2D, Dense, BatchNormalization, LeakyReLU, Input,Reshape, MaxPooling2D, Flatten, AveragePooling2D, Conv2DTranspose\r\n",
        "from tensorflow.keras.optimizers import Adam\r\n",
        "\r\n",
        "\r\n",
        "def build_G():\r\n",
        "    \r\n",
        "    model = Sequential()\r\n",
        "    model.add(Dense(2048,input_dim = noise_dim))\r\n",
        "    model.add(LeakyReLU(0.2))\r\n",
        "    model.add(Dense(8 * 8 * 256))\r\n",
        "    model.add(BatchNormalization())\r\n",
        "    model.add(LeakyReLU(0.2))\r\n",
        "    model.add(Reshape((8, 8, 256)))\r\n",
        "    model.add(Conv2D(128, kernel_size=5, padding='same'))\r\n",
        "    model.add(BatchNormalization())\r\n",
        "    model.add(LeakyReLU(0.2))\r\n",
        "    model.add(Conv2DTranspose(128, kernel_size=5, strides=2, padding='same'))\r\n",
        "    model.add(LeakyReLU(0.2))\r\n",
        "    model.add(Conv2DTranspose(64, kernel_size=5, strides=2, padding='same'))\r\n",
        "    model.add(LeakyReLU(0.2))\r\n",
        "    model.add(Conv2DTranspose(3, kernel_size=5, strides=2, padding='same', activation='tanh'))\r\n",
        "    return model\r\n",
        "G = build_G()\r\n",
        "G.summary()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 2048)              206848    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)      (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 16384)             33570816  \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 16384)             65536     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 16384)             0         \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 8, 8, 128)         819328    \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose (Conv2DTran (None, 16, 16, 128)       409728    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTr (None, 32, 32, 64)        204864    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTr (None, 64, 64, 3)         4803      \n",
            "=================================================================\n",
            "Total params: 35,282,435\n",
            "Trainable params: 35,249,411\n",
            "Non-trainable params: 33,024\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPmMCrtUcwif",
        "outputId": "4b698122-2939-4335-e0bf-f1d5900349e2"
      },
      "source": [
        "from keras.optimizers import Optimizer\r\n",
        "from keras import backend as K\r\n",
        "def build_D():\r\n",
        "    Input = tf.keras.Input([64,64,3])\r\n",
        "    nInput = Input/128 - 1\r\n",
        "    conv1 = tf.keras.layers.Conv2D(64, [5, 5], strides=(2, 2), padding=\"valid\", activation=tf.nn.relu)(nInput) #[14,14]\r\n",
        "    conv2 = tf.keras.layers.Conv2D(128, [3, 3], strides=(2, 2), padding=\"valid\", activation=tf.nn.relu)(conv1) #[7,7]\r\n",
        "    conv3 = tf.keras.layers.Conv2D(256, [3, 3], strides=(2, 2), padding=\"valid\", activation=tf.nn.relu)(conv2) #[4,4]\r\n",
        "    fc = tf.keras.layers.Flatten()(conv3)\r\n",
        "    fc1 = tf.keras.layers.Dense(256, activation=tf.nn.relu)(fc)\r\n",
        "    fc2 = tf.keras.layers.Dense(512, activation=tf.nn.relu)(fc1)\r\n",
        "    fc3 = tf.keras.layers.Dense(1024, activation=tf.nn.relu)(fc2)\r\n",
        "    out = tf.keras.layers.Dense(10, activation=None)(fc3)\r\n",
        "    # model = Sequential()\r\n",
        "    # model.add(Conv2D(64, kernel_size=5, padding='valid',input_shape = image_shape))\r\n",
        "    # model.add(BatchNormalization())\r\n",
        "    # model.add(LeakyReLU(0.2))\r\n",
        "    # model.add(AveragePooling2D(pool_size=2))\r\n",
        "    # model.add(Conv2D(128, kernel_size=3, padding='valid'))\r\n",
        "    # model.add(BatchNormalization())\r\n",
        "    # model.add(LeakyReLU(0.2))\r\n",
        "    # model.add(AveragePooling2D(pool_size=2))\r\n",
        "    # model.add(Conv2D(256, kernel_size=3, padding='valid'))\r\n",
        "    # model.add(BatchNormalization())\r\n",
        "    # model.add(LeakyReLU(0.2))\r\n",
        "    # model.add(AveragePooling2D(pool_size=2))\r\n",
        "    # model.add(Flatten())\r\n",
        "    # model.add(Dense(1024))\r\n",
        "    # model.add(BatchNormalization())\r\n",
        "    # model.add(LeakyReLU(0.2))\r\n",
        "    # model.add(Dense(1, activation='sigmoid'))\r\n",
        "    # model.compile(loss='binary_crossentropy',\r\n",
        "    #           optimizer=Adam(learning_rate=0.0002, beta_1=0.5))\r\n",
        "    # print(model)\r\n",
        "    return tf.keras.Model(inputs=Input, outputs=out)\r\n",
        "D = build_D()\r\n",
        "D.compile(loss='binary_crossentropy')\r\n",
        "D.summary()\r\n",
        "opt = PSO(D)\r\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 64, 64, 3)]       0         \n",
            "_________________________________________________________________\n",
            "tf.math.truediv (TFOpLambda) (None, 64, 64, 3)         0         \n",
            "_________________________________________________________________\n",
            "tf.math.subtract (TFOpLambda (None, 64, 64, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 30, 30, 64)        4864      \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 14, 14, 128)       73856     \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 6, 6, 256)         295168    \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               2359552   \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 512)               131584    \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1024)              525312    \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                10250     \n",
            "=================================================================\n",
            "Total params: 3,400,586\n",
            "Trainable params: 3,400,586\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "389XZ9qyc_5j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60875ba1-f64a-4724-b813-dac8683a2a18"
      },
      "source": [
        "def build_gan():\r\n",
        "  \r\n",
        "    D.trainable = False\r\n",
        "    gan_input = Input(shape=(noise_dim,))\r\n",
        "    gan_out = D(G(gan_input))\r\n",
        "    gan = Model(gan_input,gan_out)\r\n",
        "    gan.compile(loss='mean_squared_error', optimizer = 'adam')\r\n",
        "    return gan\r\n",
        "GAN = build_gan()\r\n",
        "GAN.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 100)]             0         \n",
            "_________________________________________________________________\n",
            "sequential (Sequential)      (None, 64, 64, 3)         35282435  \n",
            "_________________________________________________________________\n",
            "model (Functional)           (None, 10)                3400586   \n",
            "=================================================================\n",
            "Total params: 38,683,021\n",
            "Trainable params: 35,249,411\n",
            "Non-trainable params: 3,433,610\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJXUFJFO5J1M"
      },
      "source": [
        "def sample_noise(batch_size):\r\n",
        "    return np.random.normal(size=(batch_size, noise_dim))\r\n",
        "\r\n",
        "def smooth_pos_labels(y):\r\n",
        "    return y - 0.3 + (np.random.random(y.shape) * 0.5)\r\n",
        "\r\n",
        "def smooth_neg_labels(y):\r\n",
        "    return y + np.random.random(y.shape) * 0.3"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYWyDLNN5S4P"
      },
      "source": [
        "def load_batch(data, batch_size,index):\r\n",
        "    return data[index*batch_size: (index+1)*batch_size]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "id": "xskFoP3Wwad8",
        "outputId": "f70b1142-0dab-46bb-91f4-9b4d4fb7fb30"
      },
      "source": [
        "discriminator_loss = 0\r\n",
        "generator_loss = 0\r\n",
        "index = 0\r\n",
        "batch_size = 64  \r\n",
        "n_batches = int(input_images.shape[0] / batch_size)\r\n",
        "d_loss_logs = []\r\n",
        "g_loss_logs = []\r\n",
        "save_interval = 200\r\n",
        "size = len(input_images)\r\n",
        "def save_imgs(epoch):\r\n",
        "  r, c = 5, 5\r\n",
        "  noise = sample_noise(size)\r\n",
        "  gen_imgs = G.predict(noise)\r\n",
        "  # Rescale images 0 - 1\r\n",
        "  gen_imgs = (1/2.5) * gen_imgs + 0.5\r\n",
        "  fig, axs = plt.subplots(r, c)\r\n",
        "  cnt = 0\r\n",
        "  for i in range(r):\r\n",
        "    for j in range(c):\r\n",
        "      axs[i,j].imshow(gen_imgs[cnt, :,:,:])\r\n",
        "      axs[i,j].axis('off')\r\n",
        "      cnt += 1\r\n",
        "      fig.savefig(\"/content/drive/MyDrive/output/%d.png\" % epoch)\r\n",
        "      plt.close()\r\n",
        "def dloss():\r\n",
        "   x = input_images\r\n",
        "   noise = sample_noise(size)\r\n",
        "   generated_images = G.predict(noise)\r\n",
        "   y_real = np.ones(size)\r\n",
        "   y_real = smooth_pos_labels(y_real)\r\n",
        "   y_fake = np.zeros(size)\r\n",
        "   y_fake = smooth_neg_labels(y_fake)\r\n",
        "   d_loss_real = tf.reduce_mean(tf.keras.losses.mean_squared_error(tf.one_hot(y_real, 10, axis=-1), D(x)))\r\n",
        "   d_loss_fake =  tf.reduce_mean(tf.keras.losses.mean_squared_error(tf.one_hot(y_fake, 10, axis=-1), D(generated_images)))\r\n",
        "   #print(d_loss_real)\r\n",
        "   d_loss = d_loss_real + d_loss_fake\r\n",
        "   d_loss = tf.convert_to_tensor(d_loss)\r\n",
        "   return d_loss\r\n",
        "\r\n",
        "def train(epochs=10, batch_size=64, save_interval=1):\r\n",
        "    for i in range(epochs):\r\n",
        "      discriminator_loss = opt.minimize(dloss)\r\n",
        "      #print('dis_loss')\r\n",
        "      #print(discriminator_loss)\r\n",
        "      #print('1st epoch')\r\n",
        "      noise = sample_noise(size)\r\n",
        "      y_real = np.ones(size)\r\n",
        "      y_real = smooth_pos_labels(y_real)\r\n",
        "      generator_loss = GAN.train_on_batch(noise, y_real)\r\n",
        "      dis_loss = tf.dtypes.cast(discriminator_loss, tf.float32)\r\n",
        "      print (\"%d [D loss: %f] [G loss: %f]\" % (i, dis_loss , generator_loss))\r\n",
        "      d_loss_logs.append([i, dis_loss])\r\n",
        "      g_loss_logs.append([i, generator_loss])\r\n",
        "      if i % save_interval == 0:\r\n",
        "        save_imgs(i)\r\n",
        "\r\n",
        "\r\n",
        "    d_loss_logs_a = np.array(d_loss_logs)\r\n",
        "    g_loss_logs_a = np.array(g_loss_logs)\r\n",
        "\r\n",
        "        # At the end of training plot the losses vs epochs\r\n",
        "    plt.plot(d_loss_logs_a[:,0], d_loss_logs_a[:,1], label=\"Discriminator Loss\")\r\n",
        "    plt.plot(g_loss_logs_a[:,0], g_loss_logs_a[:,1], label=\"Generator Loss\")\r\n",
        "    plt.xlabel('Epochs')\r\n",
        "    plt.ylabel('Loss')\r\n",
        "    plt.legend()\r\n",
        "    plt.title('GAN')\r\n",
        "    plt.grid(True)\r\n",
        "    plt.show() \r\n",
        "save_interval = 200\r\n",
        "train(10,64,200)\r\n",
        "GAN.save('gan.h5')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 [D loss: 0.200260] [G loss: 0.940644]\n",
            "1 [D loss: 0.200228] [G loss: 0.921085]\n",
            "2 [D loss: 0.200284] [G loss: 0.915689]\n",
            "3 [D loss: 0.200249] [G loss: 0.905445]\n",
            "4 [D loss: 0.200258] [G loss: 0.903229]\n",
            "5 [D loss: 0.200279] [G loss: 0.920009]\n",
            "6 [D loss: 0.200287] [G loss: 0.906306]\n",
            "7 [D loss: 0.200284] [G loss: 0.907817]\n",
            "8 [D loss: 0.200293] [G loss: 0.916399]\n",
            "9 [D loss: 0.200263] [G loss: 0.918891]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}